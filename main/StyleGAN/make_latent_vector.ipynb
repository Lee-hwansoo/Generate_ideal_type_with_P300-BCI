{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_ypLQah9RxEC"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VOpZHJ-XTWx6"},"outputs":[],"source":["import os\n","\n","os.chdir(\"/content/drive/MyDrive/final_3/StyleGAN/\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GeB6wfTigaUW"},"outputs":[],"source":["!pip install lpips ninja"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uV6awVk9Rq8Q"},"outputs":[],"source":["import os\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.cuda.amp import autocast, GradScaler\n","from torchvision import models\n","from torchvision.utils import save_image\n","from torchvision import transforms\n","from collections import OrderedDict\n","import numpy as np\n","import pickle\n","import torch_utils\n","from PIL import Image\n","from lpips import LPIPS\n","from math import log10\n","from tqdm import tqdm\n","import re\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WDZrVftMRodN"},"outputs":[],"source":["device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","with open('./metrics/stylegan3-r-ffhqu-1024x1024.pkl', 'rb') as f:\n","    G = pickle.load(f)['G_ema'].to(device)\n","\n","g_all = nn.Sequential(OrderedDict([('g_mapping', G.mapping),\n","        ('g_synthesis', G.synthesis)\n","    ]))\n","\n","g_all.eval()\n","g_all.to(device)\n","g_mapping, g_synthesis = g_all[0], g_all[1]\n","print(device)\n","\n","# Upsample using bilinear interpolation\n","upsample = torch.nn.Upsample(scale_factor=256/1024, mode='bilinear').to(device)\n","\n","# MSE loss object\n","MSE_loss = nn.MSELoss(reduction=\"mean\").to(device)\n","\n","class VGG16_perceptual(torch.nn.Module):\n","    def __init__(self, requires_grad=False):\n","        super(VGG16_perceptual, self).__init__()\n","        vgg_pretrained_features = models.vgg16(pretrained=True).features\n","        self.slice1 = nn.Sequential(*list(vgg_pretrained_features)[:4])\n","        self.slice2 = nn.Sequential(*list(vgg_pretrained_features)[4:9])\n","        self.slice3 = nn.Sequential(*list(vgg_pretrained_features)[9:16])\n","        self.slice4 = nn.Sequential(*list(vgg_pretrained_features)[16:23])\n","        self.slice5 = nn.Sequential(*list(vgg_pretrained_features)[23:29])\n","        if not requires_grad:\n","            for param in self.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, X):\n","        h = self.slice1(X)\n","        h_relu_1 = h\n","        h = self.slice2(h)\n","        h_relu_2 = h\n","        h = self.slice3(h)\n","        h_relu_3 = h\n","        h = self.slice4(h)\n","        h_relu_4 = h\n","        h = self.slice5(h)\n","        h_relu_5 = h\n","        return h_relu_1, h_relu_2, h_relu_3, h_relu_4, h_relu_5\n","\n","def loss_function(syn_img, img, img_p, MSE_loss, upsample, perceptual, lpips):\n","    syn_img_p = upsample(syn_img)\n","    syn0, syn1, syn2, syn3, syn4 = perceptual(syn_img_p)\n","    r0, r1, r2, r3, r4 = perceptual(img_p)\n","    mse = MSE_loss(syn_img, img)\n","    lpips_distance = lpips(syn_img, img)\n","\n","    per_loss = 0\n","    per_loss += MSE_loss(syn0, r0)\n","    per_loss += MSE_loss(syn1, r1)\n","    per_loss += MSE_loss(syn2, r2)\n","    per_loss += MSE_loss(syn3, r3)\n","    per_loss += MSE_loss(syn4, r4)\n","\n","    return mse, per_loss, lpips_distance.detach().cpu().view(-1).item()\n","\n","def PSNR(mse, flag=0):\n","    if flag == 0:\n","        psnr = 10 * log10(1 / mse.item())\n","    return psnr\n","\n","def embedding_Hierarchical(image, img_num):\n","    img_p = upsample(image.clone())\n","    perceptual = VGG16_perceptual().to(device)\n","    latent_w = torch.zeros((1, 512), requires_grad=True, device=device)\n","    optimizer = optim.Adam({latent_w}, lr=0.01, betas=(0.9, 0.999), eps=1e-8)\n","    lpips = LPIPS(pretrained=True, net='vgg', version='0.1').to(device)\n","\n","    loss_ = []\n","    loss_psnr = []\n","    for e in tqdm(range(4000), desc=f'Optimizing Phase 1 - Image {img_num}'):\n","        optimizer.zero_grad()\n","        latent_w1 = latent_w.unsqueeze(1).expand(-1, 16, -1)\n","        syn_img = g_synthesis(latent_w1)\n","        syn_img = (syn_img + 1.0) / 2.0\n","        mse, per_loss, lpips_distance = loss_function(syn_img, image, img_p, MSE_loss, upsample, perceptual, lpips)\n","        psnr = PSNR(mse, flag=0)\n","        loss = mse + per_loss + lpips_distance\n","        loss.backward()\n","        optimizer.step()\n","        loss_np = loss.detach().cpu().numpy()\n","        loss_p = per_loss.detach().cpu().numpy()\n","        loss_m = mse.detach().cpu().numpy()\n","        loss_lpips = lpips_distance\n","        loss_psnr.append(psnr)\n","        loss_.append(loss_np)\n","        if (e + 1) % 500 == 0:\n","            print(\"iter{}: loss -- {}, lpips_loss -- {}, mse_loss -- {},  percep_loss -- {}, psnr -- {}\".format(e + 1, loss_np, loss_lpips, loss_m, loss_p, psnr))\n","            save_image(syn_img.clamp(0, 1), f\"./save_images/Hier_pass_morphP1-{img_num}-{e + 1}.png\")\n","\n","    latent_w1 = latent_w.unsqueeze(1).expand(-1, 16, -1)\n","    latent_w1 = torch.tensor(latent_w1, requires_grad=True)\n","    optimizer = optim.Adam({latent_w1}, lr=0.01, betas=(0.9, 0.999), eps=1e-8)\n","    for e in tqdm(range(6000), desc=f'Optimizing Phase 2 - Image {img_num}'):\n","        optimizer.zero_grad()\n","        syn_img = g_synthesis(latent_w1)\n","        syn_img = (syn_img + 1.0) / 2.0\n","        mse, per_loss, lpips_distance = loss_function(syn_img, image, img_p, MSE_loss, upsample, perceptual, lpips)\n","        psnr = PSNR(mse, flag=0)\n","        loss = mse + per_loss + lpips_distance\n","        loss.backward()\n","        optimizer.step()\n","        loss_np = loss.detach().cpu().numpy()\n","        loss_p = per_loss.detach().cpu().numpy()\n","        loss_m = mse.detach().cpu().numpy()\n","        loss_psnr.append(psnr)\n","        loss_.append(loss_np)\n","        if (e + 1) % 500 == 0:\n","            print(\"iter{}: loss -- {}, lpips_loss -- {}, mse_loss -- {},  percep_loss -- {}, psnr -- {}\".format(e + 1, loss_np, loss_lpips, loss_m, loss_p, psnr))\n","            save_image(syn_img.clamp(0, 1), f\"./save_images/Hier_pass_morphP2-{img_num}-{e + 1}.png\")\n","\n","    return latent_w1\n","\n","# Setup images\n","input_folder = \"./images\"\n","output_folder = \"./latent\"\n","if not os.path.exists(output_folder):\n","    os.makedirs(output_folder)\n","\n","files = os.listdir(input_folder)\n","image_files = [file for file in files if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))]\n","sorted_files = sorted(image_files, key=lambda x: int(re.search(r'\\d+', x).group()))\n","for idx, image_file in enumerate(sorted_files):\n","    # 정규표현식을 사용하여 파일 이름에서 숫자 추출\n","    match = re.search(r'\\d+', image_file)\n","    if match:\n","        number = int(match.group())\n","        image_path = os.path.join(input_folder, image_file)\n","        latent_filename = f\"latent{number}.npy\"\n","        latent_path = os.path.join(output_folder, latent_filename)\n","\n","        with open(image_path, \"rb\") as f:\n","            image = Image.open(f).convert(\"RGB\")\n","\n","        transform = transforms.Compose([transforms.ToTensor()])\n","        image = transform(image)\n","        image = image.unsqueeze(0)\n","        image = image.to(device)\n","\n","        latent_vector = embedding_Hierarchical(image, number)\n","        np.save(latent_path, latent_vector.detach().cpu().numpy())\n","    else:\n","        print(f\"파일: {image_file}, 파일 이름에서 숫자를 찾을 수 없습니다.\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
